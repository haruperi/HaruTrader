# Instructions

During your interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again. 

You should also use the `.cursorrules` file as a Scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the Scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the Scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Tools

Note all the tools are in python. So in the case you need to do batch processing, you can always consult the python files and write your own script.

## Screenshot Verification

The screenshot verification workflow allows you to capture screenshots of web pages and verify their appearance using LLMs. The following tools are available:

1. Screenshot Capture:
```bash
venv/bin/python tools/screenshot_utils.py URL [--output OUTPUT] [--width WIDTH] [--height HEIGHT]
```

2. LLM Verification with Images:
```bash
venv/bin/python tools/llm_api.py --prompt "Your verification question" --provider {openai|anthropic} --image path/to/screenshot.png
```

Example workflow:
```python
from screenshot_utils import take_screenshot_sync
from llm_api import query_llm

# Take a screenshot

screenshot_path = take_screenshot_sync('https://example.com', 'screenshot.png')

# Verify with LLM

response = query_llm(
    "What is the background color and title of this webpage?",
    provider="openai",  # or "anthropic"
    image_path=screenshot_path
)
print(response)
```

## LLM

You always have an LLM at your side to help you with the task. For simple tasks, you could invoke the LLM by running the following command:
```
venv/bin/python ./tools/llm_api.py --prompt "What is the capital of France?" --provider "anthropic"
```

The LLM API supports multiple providers:
- OpenAI (default, model: gpt-4o)
- Azure OpenAI (model: configured via AZURE_OPENAI_MODEL_DEPLOYMENT in .env file, defaults to gpt-4o-ms)
- DeepSeek (model: deepseek-chat)
- Anthropic (model: claude-3-sonnet-20240229)
- Gemini (model: gemini-pro)
- Local LLM (model: Qwen/Qwen2.5-32B-Instruct-AWQ)

But usually it's a better idea to check the content of the file and use the APIs in the `tools/llm_api.py` file to invoke the LLM if needed.

## Web browser

You could use the `tools/web_scraper.py` file to scrape the web.
```
venv/bin/python ./tools/web_scraper.py --max-concurrent 3 URL1 URL2 URL3
```
This will output the content of the web pages.

## Search engine

You could use the `tools/search_engine.py` file to search the web.
```
venv/bin/python ./tools/search_engine.py "your search keywords"
```
This will output the search results in the following format:
```
URL: https://example.com
Title: This is the title of the search result
Snippet: This is a snippet of the search result
```
If needed, you can further use the `web_scraper.py` file to scrape the web page content.

# Development Guidelines

1. Always activate the virtual environment before working on the project
2. Add new dependencies to requirements.txt
3. Keep code organized and well-documented
4. Follow PEP 8 style guidelines for Python code
5. Keep your code DRY (Dont Repeat Yourself)

# Lessons

## User Specified Lessons

- You have a python venv in ./venv. Use it.
- Include info useful for debugging in the program output.
- Read the file before you try to edit it.
- Due to Cursor's limit, when you use `git` and `gh` and need to submit a multiline commit message, first write the message in a file, and then use `git commit -F <filename>` or similar command to commit. And then remove the file. Include "[Cursor] " in the commit message and PR title.
- Always implement proper logging in all modules following these guidelines:
  1. Import the logger at the top of each module: `from app.utils import get_logger`
  2. Create a module-specific logger: `logger = get_logger(__name__)`
  3. Use appropriate log levels:
     - DEBUG: Detailed information for debugging
     - INFO: Confirmation that things are working as expected
     - WARNING: Indication that something unexpected happened but the application is still working
     - ERROR: Due to a more serious problem, the application couldn't perform a function
     - CRITICAL: A serious error indicating the application may be unable to continue running
  4. Include context in log messages (e.g., function parameters, return values, object states)
  5. Log the start and end of important operations
  6. Log all exceptions with traceback information using `logger.exception()` or `logger.error(exc_info=True)`
  7. Use structured logging for machine-parseable logs when appropriate
- Implement defensive programming to handle circular imports:
  1. Use try/except blocks for imports that might cause circular dependencies
  2. Implement fallback mechanisms for critical utilities like logging
  3. Follow the module hierarchy defined in docs/dependency_management.md
  4. Use late imports inside functions when necessary
  5. Use dependency injection to pass higher-level components to lower-level ones
  6. Test imports thoroughly before committing code

## Cursor learned

- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- Add debug information to stderr while keeping the main output clean in stdout for better pipeline integration
- When using seaborn styles in matplotlib, use 'seaborn-v0_8' instead of 'seaborn' as the style name due to recent seaborn version changes
- Use 'gpt-4o' as the model name for OpenAI's GPT-4 with vision capabilities

# Scratchpad

## Current Task: Project Reorganization
Reorganizing the project structure to follow best practices.

### Plan:
## Phase 1: Project Setup and Core Infrastructure
[X] Initial Project Setup
  - [X] Create virtual environment and install Python 3.13.2
  - [X] Set up requirements.txt with initial dependencies
  - [X] Create .env.example with required environment variables
  - [X] Set up project structure according to architecture diagram
  - [X] Initialize git repository and set up .gitignore

[ ] Core Infrastructure Setup
  - [X] Set up logging configuration in app/utils/logger.py
  - [X] Implement timeutils.py for timezone handling
    - [X] Implement core functionality
    - [X] Add comprehensive test suite in tests/unit/utils/test_timeutils.py
  - [ ] Create validation.py for input validation
  - [ ] Set up TimescaleDB connection and models
  - [ ] Configure OAuth2 authentication system

## Phase 2: MT5 Integration and Core Trading Components
[ ] MT5 Integration (app/core/mt5_data.py)
  - [ ] Implement MT5 client connection
  - [ ] Set up market data operations
  - [ ] Create data retrieval functions
  - [ ] Implement error handling and reconnection logic

[ ] Trader Module (app/trader/)
  - [ ] Implement order.py for order placement
  - [ ] Create position.py for position management
  - [ ] Develop risk.py for risk calculations
  - [ ] Set up history.py for trade history retrieval

[ ] Core Notification System (app/core/notification.py)
  - [ ] Set up Telegram bot integration
  - [ ] Implement message formatting
  - [ ] Create notification queue system
  - [ ] Add error reporting functionality

## Phase 3: Strategy Development
[ ] Base Strategy Framework (app/strategy/)
  - [ ] Create base.py with strategy interface
  - [ ] Implement indicators.py with technical indicators
  - [ ] Set up risk_management.py
  - [ ] Develop screener.py for symbol scanning

[ ] Initial Strategy Implementations
  - [ ] Create trend_following.py
  - [ ] Implement mean_reversion.py
  - [ ] Develop breakout.py
  - [ ] Add strategy parameter management

## Phase 4: Backtesting System
[ ] Backtesting Engine (app/backtest/)
  - [ ] Create event-based engine.py
  - [ ] Implement optimizer.py
  - [ ] Set up walk_forward.py
  - [ ] Add monte_carlo.py simulation
  - [ ] Implement cross_validation.py

## Phase 5: Live Trading System
[ ] Live Trading Module (app/live_trading/)
  - [ ] Develop executor.py for real-time execution
  - [ ] Create monitor.py for performance tracking
  - [ ] Implement recovery.py for failover
  - [ ] Add concurrent task handling

## Phase 6: Dashboard Development
[ ] Web Dashboard (app/dashboard/)
  - [ ] Set up Flask/FastAPI application
  - [ ] Create authentication system
  - [ ] Implement account endpoints
  - [ ] Add performance metrics endpoints
  - [ ] Develop strategy management endpoints
  - [ ] Create HTML templates and static assets

## Phase 7: Testing and Documentation
[ ] Testing Infrastructure
  - [ ] Set up pytest configuration
  - [ ] Create unit tests for each module
  - [ ] Implement integration tests
  - [ ] Add end-to-end tests
  - [ ] Create test fixtures and utilities

[ ] Documentation
  - [ ] Write architecture.md
  - [ ] Create API documentation
  - [ ] Develop deployment guide
  - [ ] Write user guide
  - [ ] Add inline code documentation

## Phase 8: Deployment and Monitoring
[ ] Deployment Setup
  - [ ] Create Docker configuration
  - [ ] Set up CI/CD pipeline
  - [ ] Configure production environment
  - [ ] Implement backup system

[ ] Monitoring System
  - [ ] Set up Grafana dashboards
  - [ ] Implement system health checks
  - [ ] Create performance monitoring
  - [ ] Add alert system

## Phase 9: Security and Optimization
[ ] Security Implementation
  - [ ] Implement API key encryption
  - [ ] Set up secure communication
  - [ ] Add audit logging
  - [ ] Implement access control

[ ] Performance Optimization
  - [ ] Optimize database queries
  - [ ] Improve concurrent operations
  - [ ] Enhance error handling
  - [ ] Add caching where appropriate

## Phase 10: Additional Features and Integration
[ ] External Data Integration
  - [ ] Add Investpy integration
  - [ ] Implement Forex Factory data collection
  - [ ] Set up social media sentiment analysis
  - [ ] Create news feed integration

[ ] Additional Features
  - [ ] Implement portfolio management
  - [ ] Add risk reporting
  - [ ] Create performance analytics
  - [ ] Develop custom indicators

### Progress:
✓ Moved all test files from examples to tests directory:
  - Renamed simple_logger_test.py to test_logger.py
  - Copied test_market_data.py, test_fundamental_data.py, and test_market_data_mock.py
  - Copied README.md

✓ Deleted examples directory

✓ Deleted scripts directory

✓ Updated .cursorrules with testing rules:
  - Added guidelines for test organization
  - Added naming conventions for test files, classes, and methods

✓ Updated tests/README.md:
  - Updated file paths and commands
  - Added information about test organization and running tests

✓ Consolidated notification functionality:
  - Moved convenience functions from app/utils/notify.py to app/core/notification.py
  - Deleted app/utils/notify.py and app/utils/notification.py
  - Updated imports in app/trader/trade.py

✓ Deleted all log files for a fresh start

Next: Continue implementing the remaining methods in the trade.py file:
  - Implement modify_order method
  - Implement cancel_order method
  - Implement get_order_status method
  - Implement get_pending_orders method
  - Implement calculate_position_size method

## Testing Rules

All tests must be organized in the following directory structure under the tests folder:

### Unit Tests (`tests/unit/`)
- Purpose: Test individual components/functions in isolation
- Scope: Single unit of code (class, function, method)
- Dependencies: Usually mocked/stubbed
- Examples:
  - `tests/unit/utils/test_logger.py` - Tests individual logger functions
  - `tests/unit/core/test_mt5_data.py` - Tests MT5 data parsing functions
  - `tests/unit/trader/test_position.py` - Tests position calculation logic

### Integration Tests (`tests/integration/`)
- Purpose: Test how components work together
- Scope: Multiple components/services
- Dependencies: Real or test doubles
- Examples:
  - `tests/integration/test_mt5_trader.py` - Tests MT5 client with trading logic
  - `tests/integration/test_db_logging.py` - Tests logger with database
  - `tests/integration/test_strategy_execution.py` - Tests strategy with live data feed

### End-to-End Tests (`tests/e2e/`)
- Purpose: Test complete workflows
- Scope: Entire system
- Dependencies: Real systems
- Examples:
  - `tests/e2e/test_trading_workflow.py` - Complete trade lifecycle
  - `tests/e2e/test_backtest_workflow.py` - Full backtest process
  - `tests/e2e/test_dashboard_workflow.py` - Complete dashboard interaction

### Fixtures (`tests/fixtures/`)
- Purpose: Provide reusable test data and setup
- Types:
  - Data fixtures: Sample data for tests (e.g., OHLCV data)
  - Object fixtures: Pre-configured objects (e.g., MT5 API mock)
  - Environment fixtures: Test environment setup (e.g., test database)
- Examples:
  - `tests/fixtures/market_data.py` - Sample OHLCV data
  - `tests/fixtures/mt5_mock.py` - MT5 API mock
  - `tests/fixtures/test_db.py` - Test database setup

### Test File Organization
Test files must follow these naming conventions:
- All test files must be named `test_*.py` to be automatically discovered by test runners
- Test classes must be named `Test*`
- Test methods must be named `test_*`
- Unit test files should mirror the structure of the source code:
  - For a source file at `app/utils/logger.py`, the test should be at `tests/unit/utils/test_logger.py`
  - For a source file at `app/core/trade.py`, the test should be at `tests/unit/core/test_trade.py`

### Test Organization Guidelines
- Keep test files focused and cohesive
- Group related test cases in test classes
- Use descriptive test names that explain the scenario being tested
- Follow the Arrange-Act-Assert pattern in test methods
- Use appropriate fixtures for test setup and teardown
- Mock external dependencies in unit tests

### Tool Tests (`tests/tools/`)
- Purpose: Test development tools and scripts
- Scope: Development utilities and helper scripts
- Dependencies: Usually real dependencies (not mocked)
- Examples:
  - `tests/tools/test_logger.py` - Manual logger testing script
  - `tests/tools/test_db_setup.py` - Database setup verification
  - `tests/tools/test_env_check.py` - Environment setup verification

